{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "904b5911-b647-448b-961f-a93b9c44b895",
   "metadata": {},
   "source": [
    "# Build GA 2020 Source Data\n",
    "\n",
    "This notebook accepts the Census 2020 DHC data and polling location data to build a csv to be used with scip.  Clone this notebook for new states or years.\n",
    "\n",
    "## Census Data:\n",
    "\n",
    "### 2020 Redistricting [P4 group](https://api.census.gov/data/2010/dec/sf1/groups/P4.html)\n",
    "[HISPANIC OR LATINO, AND NOT HISPANIC OR LATINO BY RACE FOR THE POPULATION 18 YEARS AND OVER](https://data.census.gov/table?g=050XX00US13135$1000000&d=DEC+Redistricting+Data+(PL+94-171)&tid=DECENNIALPL2020.P4)\n",
    "1. Select Geography:\n",
    "   1. Filter for Geography -> Blocks -> State -> County Name, State -> All Blocks within County Name, State\n",
    "   1. If asked to select table vintage, select 2020;  DEC Redistricting Data (PL-94-171)\n",
    "\n",
    "Columns we want from P4:\n",
    "* Total population\n",
    "* Total hispanic\n",
    "* Total non-hispanic\n",
    "\n",
    "### 2020 Redistricting [P3 group](https://api.census.gov/data/2010/dec/sf1/groups/P3.html)\n",
    "Data source that includes Race and geography: \n",
    "[RACE FOR THE POPULATION 18 YEARS AND OVER](https://data.census.gov/table?q=P3:+RACE+FOR+THE+POPULATION+18+YEARS+AND+OVER&tid=DECENNIALPL2020.P3)\n",
    "1. Select Geography:\n",
    "   1. Filter for Geography -> Blocks -> State -> County Name, State -> All Blocks within County Name, State\n",
    "   1. If asked to select table vintage, select 2020;  DEC Redistricting Data (PL-94-171)\n",
    "\n",
    "Colums we want from P3:\n",
    "* White alone\n",
    "* Black or African American alone\n",
    "* American Indian And Alaska Native alone\n",
    "* Asian alone\n",
    "* Native Hawaiian and Other Pacific Islander alone\n",
    "* Some Other Race alone\n",
    "* Two or More Races\n",
    "\n",
    "\n",
    "### 2020 Tiger/Line Shapefiles: Blocks (2020) \n",
    "Source Data https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.2020.html#list-tab-790442341\n",
    "* Scroll down to FTP Archiv by State\n",
    "* Click on desired States\n",
    "* Click on desired FIPS Code for the County\n",
    "* Download that *_tablock20.zip and the *_bg20.zip files\n",
    "\n",
    "Documentation: https://www.census.gov/programs-surveys/geography/technical-documentation/complete-technical-documentation/tiger-geo-line/2020.html\n",
    "\n",
    "Columns we want from blocks:\n",
    "* GEO_ID - obtained by converting values in GEOID20 column and preppending \"1000000US\", e.g. 131510703153004 -> 1000000US131510703153004\n",
    "* geometry - the polygon of the block\n",
    "* INTPTLAT20 - latitude of block centroid\n",
    "* INTPTLON20 - longitude of block centroid\n",
    "\n",
    "**Susama:** please verify the above\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\n",
    "## Redistricting source data:\n",
    "1. Download desired Census Data\n",
    "   1. P4 zip file from Census\n",
    "   1. P3 zip file from Census\n",
    "   1. Recommend downloading one county's worth of data at a time.\n",
    "1. Create a directory to datasets/census/redistricting/County_Name_ST **Chad**: This is a change to  your folder structure. I want to indicate geography in the name\n",
    "   1. E.g datasets/census/redistricting/Gwinnett_GA\n",
    "   1. Key files: DECENNIALPL2020.P3-Data.csv; DECENNIALPL2020.P4-Data.csv\n",
    "   1. Note, this requires one to filter for an individual county from the census.\n",
    "1. Unzip the downloaded file P11 file zip to the directory \n",
    "\n",
    "## Tiger/Line Shapefile\n",
    "1. Download desired Tiger/Line file zip file from Census\n",
    "1. Create a directory to datasets/census/tiger/County_Name_St e.g. datasets/census/tiger/Gwinnett_GA\n",
    "1. Unzip the downloaded Tiger/Line zip file to the directory \n",
    "    \n",
    "## Run cells\n",
    "1. Update constants such as P11_SOURCE_FILE, P3_SOURCE_FILE, BLOCK_SOURCE_FILE as needed\n",
    "1. Run each cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5027b87-ac41-4bf9-80b1-056a59a54865",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the P11 csv source data into a data frame and filter out unneeded columns\n",
    "\n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "from haversine import haversine, Unit\n",
    "import geopandas as gpd\n",
    "\n",
    "P4_SOURCE_FILE = 'datasets/census/redistricting/Gwinnett_GA/DECENNIALPL2020.P4-Data.csv'\n",
    "P3_SOURCE_FILE = 'datasets/census/redistricting/Gwinnett_GA/DECENNIALPL2020.P3-Data.csv'\n",
    "\n",
    "# The column in the P4 and P4data that contains the GEO id.  This will be used later to join\n",
    "# against the Block Shape File\n",
    "P4_GEOID = 'GEO_ID'\n",
    "P3_GEOID = 'GEO_ID'\n",
    "\n",
    "# Prefix to add to Shape files to join them with this P11.  Note this\n",
    "# needs to match the prefix found in GEO_ID output from this cell.\n",
    "GEO_ID_PREFIX = '1000000US'\n",
    "\n",
    "PL_P4_COLUMNS = [\n",
    "    P4_GEOID,\n",
    "    'NAME',\n",
    "    'P4_001N', # Total population\n",
    "    'P4_002N', # Total hispanic\n",
    "    'P4_003N', # Total non-hispanic\n",
    "]\n",
    "\n",
    "PL_P3_COLUMNS = [\n",
    "    P3_GEOID,\n",
    "    'NAME',\n",
    "    'P3_001N', # Total population\n",
    "    'P3_002N', # White alone\n",
    "    'P3_003N', # Black or African American alone\n",
    "    'P3_004N', # American Indian or Alaska Native alone\n",
    "    'P3_005N', # Asian alone\n",
    "    'P3_006N', # Native Hawaiian and Other Pacific Islander alone\n",
    "    'P3_007N', # Some other race alone \n",
    "    'P3_008N', # Two or More Races   \n",
    "]\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "#print('DHC P11 File')\n",
    "#print(f'  Source {P11_SOURCE_FILE}')\n",
    "\n",
    "p4_df = pd.read_csv(\n",
    "    P4_SOURCE_FILE,\n",
    "    header=[0,1], # DHC files have two headers rows when exported to CSV - tell pandas to only take top one\n",
    "    low_memory=False, # files are too big, set this to False to prevent errors\n",
    "    # nrows=10, # limit rows loaded - testing purposes only\n",
    ")\n",
    "\n",
    "p3_df = pd.read_csv(\n",
    "    P3_SOURCE_FILE,\n",
    "    header=[0,1], # DHC files have two headers rows when exported to CSV - tell pandas to take top one\n",
    "    low_memory=False, # files are too big, set this to False to prevent errors\n",
    "    # nrows=10, # limit rows loaded - testing purposes only\n",
    ")\n",
    "\n",
    "\n",
    "# Filter out the un-needed columns and keep only one header\n",
    "p4_df = p4_df[PL_P4_COLUMNS]\n",
    "p4_df.columns = p4_df.columns=[multicols[0] for multicols in p4_df.columns]\n",
    "\n",
    "p3_df = p3_df[PL_P3_COLUMNS]\n",
    "p3_df.columns = p3_df.columns=[multicols[0] for multicols in p3_df.columns]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec9b87ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GEO_ID', 'NAME', 'hispanic', 'non-hispanic', 'population', 'white',\n",
       "       'black', 'native', 'asian', 'pacific_islander', 'other',\n",
       "       'multiple_races'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merge the data sets to get a joint demographics set\n",
    "demographics = p4_df.merge(p3_df, left_on=['GEO_ID', 'NAME'], right_on=['GEO_ID', 'NAME'],how = 'outer')\n",
    "\n",
    "#Consistency check for the data pull\n",
    "demographics['Pop_diff'] = demographics.P4_001N- demographics.P3_001N\n",
    "if demographics.loc[demographics.Pop_diff != 0].shape[0]!=0:\n",
    "    raise ValueError('Populations different in P3 and P4. Are both pulled from the voting age universe?')\n",
    "\n",
    "#Change column names\n",
    "demographics.drop(['P4_001N', 'Pop_diff'], axis =1, inplace = True)\n",
    "demographics = demographics.rename(columns = {'P4_002N': 'hispanic', 'P4_003N':'non-hispanic', 'P3_001N':'population', 'P3_002N':'white', 'P3_003N':'black', \n",
    "                      'P3_004N':'native', 'P3_005N':'asian', 'P3_006N':'pacific_islander', 'P3_007N':'other', 'P3_008N':'multiple_races'})\n",
    "#Note, Hispanic is an ethnicity, not a race. The P4 columns add to the total population. The P3 columns add to the total population\n",
    "demographics.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "283d1c07-85e4-467a-8099-211e332bbdb9",
   "metadata": {},
   "outputs": [
    {
     "ename": "DriverError",
     "evalue": "datasets/census/tiger/Gwinnett_GA/tl_2020_13135_tabblock20.shp: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCPLE_OpenFailedError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[1;32mfiona\\ogrext.pyx:136\u001b[0m, in \u001b[0;36mfiona.ogrext.gdal_open_vector\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mfiona\\_err.pyx:291\u001b[0m, in \u001b[0;36mfiona._err.exc_wrap_pointer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mCPLE_OpenFailedError\u001b[0m: datasets/census/tiger/Gwinnett_GA/tl_2020_13135_tabblock20.shp: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mDriverError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 11\u001b[0m\n\u001b[0;32m      3\u001b[0m BLOCK_SOURCE_FILE \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdatasets/census/tiger/Gwinnett_GA/tl_2020_13135_tabblock20.shp\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      5\u001b[0m BLOCK_SHAPE_COLS \u001b[39m=\u001b[39m [\n\u001b[0;32m      6\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mGEOID20\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      7\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mINTPTLAT20\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[0;32m      8\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mINTPTLON20\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      9\u001b[0m ]\n\u001b[1;32m---> 11\u001b[0m blocks_gdf \u001b[39m=\u001b[39m gpd\u001b[39m.\u001b[39;49mread_file(BLOCK_SOURCE_FILE)\n\u001b[0;32m     12\u001b[0m blocks_gdf \u001b[39m=\u001b[39m blocks_gdf[BLOCK_SHAPE_COLS]\n",
      "File \u001b[1;32mc:\\Users\\ganga\\anaconda3\\envs\\equitable-polls\\Lib\\site-packages\\geopandas\\io\\file.py:160\u001b[0m, in \u001b[0;36m_read_file\u001b[1;34m(filename, bbox, mask, rows, **kwargs)\u001b[0m\n\u001b[0;32m    157\u001b[0m     reader \u001b[39m=\u001b[39m fiona\u001b[39m.\u001b[39mopen\n\u001b[0;32m    159\u001b[0m \u001b[39mwith\u001b[39;00m fiona_env():\n\u001b[1;32m--> 160\u001b[0m     \u001b[39mwith\u001b[39;00m reader(path_or_bytes, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs) \u001b[39mas\u001b[39;00m features:\n\u001b[0;32m    161\u001b[0m \n\u001b[0;32m    162\u001b[0m         \u001b[39m# In a future Fiona release the crs attribute of features will\u001b[39;00m\n\u001b[0;32m    163\u001b[0m         \u001b[39m# no longer be a dict, but will behave like a dict. So this should\u001b[39;00m\n\u001b[0;32m    164\u001b[0m         \u001b[39m# be forwards compatible\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         crs \u001b[39m=\u001b[39m (\n\u001b[0;32m    166\u001b[0m             features\u001b[39m.\u001b[39mcrs[\u001b[39m\"\u001b[39m\u001b[39minit\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    167\u001b[0m             \u001b[39mif\u001b[39;00m features\u001b[39m.\u001b[39mcrs \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39minit\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m features\u001b[39m.\u001b[39mcrs\n\u001b[0;32m    168\u001b[0m             \u001b[39melse\u001b[39;00m features\u001b[39m.\u001b[39mcrs_wkt\n\u001b[0;32m    169\u001b[0m         )\n\u001b[0;32m    171\u001b[0m         \u001b[39m# handle loading the bounding box\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ganga\\anaconda3\\envs\\equitable-polls\\Lib\\site-packages\\fiona\\env.py:457\u001b[0m, in \u001b[0;36mensure_env_with_credentials.<locals>.wrapper\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    454\u001b[0m     session \u001b[39m=\u001b[39m DummySession()\n\u001b[0;32m    456\u001b[0m \u001b[39mwith\u001b[39;00m env_ctor(session\u001b[39m=\u001b[39msession):\n\u001b[1;32m--> 457\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[1;32mc:\\Users\\ganga\\anaconda3\\envs\\equitable-polls\\Lib\\site-packages\\fiona\\__init__.py:335\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, driver, schema, crs, encoding, layer, vfs, enabled_drivers, crs_wkt, allow_unsupported_drivers, **kwargs)\u001b[0m\n\u001b[0;32m    332\u001b[0m     path \u001b[39m=\u001b[39m parse_path(fp)\n\u001b[0;32m    334\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39ma\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 335\u001b[0m     colxn \u001b[39m=\u001b[39m Collection(\n\u001b[0;32m    336\u001b[0m         path,\n\u001b[0;32m    337\u001b[0m         mode,\n\u001b[0;32m    338\u001b[0m         driver\u001b[39m=\u001b[39;49mdriver,\n\u001b[0;32m    339\u001b[0m         encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m    340\u001b[0m         layer\u001b[39m=\u001b[39;49mlayer,\n\u001b[0;32m    341\u001b[0m         enabled_drivers\u001b[39m=\u001b[39;49menabled_drivers,\n\u001b[0;32m    342\u001b[0m         allow_unsupported_drivers\u001b[39m=\u001b[39;49mallow_unsupported_drivers,\n\u001b[0;32m    343\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[0;32m    344\u001b[0m     )\n\u001b[0;32m    345\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    346\u001b[0m     colxn \u001b[39m=\u001b[39m Collection(\n\u001b[0;32m    347\u001b[0m         path,\n\u001b[0;32m    348\u001b[0m         mode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    358\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\ganga\\anaconda3\\envs\\equitable-polls\\Lib\\site-packages\\fiona\\collection.py:234\u001b[0m, in \u001b[0;36mCollection.__init__\u001b[1;34m(self, path, mode, driver, schema, crs, encoding, layer, vsi, archive, enabled_drivers, crs_wkt, ignore_fields, ignore_geometry, include_fields, wkt_version, allow_unsupported_drivers, **kwargs)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    233\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession \u001b[39m=\u001b[39m Session()\n\u001b[1;32m--> 234\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mstart(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    235\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39ma\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    236\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession \u001b[39m=\u001b[39m WritingSession()\n",
      "File \u001b[1;32mfiona\\ogrext.pyx:587\u001b[0m, in \u001b[0;36mfiona.ogrext.Session.start\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mfiona\\ogrext.pyx:143\u001b[0m, in \u001b[0;36mfiona.ogrext.gdal_open_vector\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mDriverError\u001b[0m: datasets/census/tiger/Gwinnett_GA/tl_2020_13135_tabblock20.shp: No such file or directory"
     ]
    }
   ],
   "source": [
    "# Load the census block shape file using geopandas and filter out unneeded columns\n",
    "\n",
    "BLOCK_SOURCE_FILE = 'datasets/census/tiger/Gwinnett_GA/tl_2020_13135_tabblock20.shp'\n",
    "\n",
    "BLOCK_SHAPE_COLS = [\n",
    "    'GEOID20',\n",
    "    'INTPTLAT20', \n",
    "    'INTPTLON20',\n",
    "]\n",
    "\n",
    "blocks_gdf = gpd.read_file(BLOCK_SOURCE_FILE)\n",
    "blocks_gdf = blocks_gdf[BLOCK_SHAPE_COLS]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c040b938-6549-4d87-9171-28d4c6f67d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GEO_ID               object\n",
       "NAME                 object\n",
       "hispanic              int64\n",
       "non-hispanic          int64\n",
       "population            int64\n",
       "white                 int64\n",
       "black                 int64\n",
       "native                int64\n",
       "asian                 int64\n",
       "pacific_islander      int64\n",
       "other                 int64\n",
       "multiple_races        int64\n",
       "GEOID20              object\n",
       "INTPTLAT20          float64\n",
       "INTPTLON20          float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the PL demographic data with the block groups shape file using a join on GEO IDs\n",
    "#drop geo_id_prefix\n",
    "demographics['GEO_ID'] = demographics['GEO_ID'].str.replace(GEO_ID_PREFIX, '')\n",
    "\n",
    "combined_df = demographics.merge(blocks_gdf, left_on='GEO_ID', right_on = 'GEOID20',how='left')\n",
    "\n",
    "#make lat/ long floats\n",
    "combined_df.INTPTLAT20 = combined_df.INTPTLAT20.astype(float)\n",
    "combined_df.INTPTLON20 = combined_df.INTPTLON20.astype(float)\n",
    "\n",
    "combined_df.dtypes\n",
    "#make combined_df into geopandas objects\n",
    "\n",
    "#combined_df = gpd.GeoDataFrame(\n",
    "#    combined_df, geometry=gpd.points_from_xy(combined_df.INTPTLON20, combined_df.INTPTLAT20), crs=\"ESRI:103263\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc492a05-3bd6-431c-a67c-2b87730b78ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>Address</th>\n",
       "      <th>Location type</th>\n",
       "      <th>dest_type</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aurora Theater</td>\n",
       "      <td>128 E Pike St</td>\n",
       "      <td>Potential</td>\n",
       "      <td>potential</td>\n",
       "      <td>33.95711</td>\n",
       "      <td>-83.98723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bogan Park Community Recreation Center</td>\n",
       "      <td>2723 North Bogan Road</td>\n",
       "      <td>EV_2022_2020</td>\n",
       "      <td>polling</td>\n",
       "      <td>34.10593</td>\n",
       "      <td>-83.96820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dacula Park Activity Building</td>\n",
       "      <td>2735 Old Auburn Avenue</td>\n",
       "      <td>EV_2022_2020</td>\n",
       "      <td>polling</td>\n",
       "      <td>33.99610</td>\n",
       "      <td>-83.89283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gas South-Hudgens Center for Arts</td>\n",
       "      <td>6400 Sugarloaf Parkway Building 300</td>\n",
       "      <td>EV_2022</td>\n",
       "      <td>polling</td>\n",
       "      <td>33.99165</td>\n",
       "      <td>-84.09391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>George Pierce Park Community Recreation Center</td>\n",
       "      <td>55 Buford Highway</td>\n",
       "      <td>EV_2022_2020</td>\n",
       "      <td>polling</td>\n",
       "      <td>34.05925</td>\n",
       "      <td>-84.05714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Location   \n",
       "0                                  Aurora Theater  \\\n",
       "1          Bogan Park Community Recreation Center   \n",
       "2                   Dacula Park Activity Building   \n",
       "3               Gas South-Hudgens Center for Arts   \n",
       "4  George Pierce Park Community Recreation Center   \n",
       "\n",
       "                               Address Location type  dest_type  Latitude   \n",
       "0                        128 E Pike St     Potential  potential  33.95711  \\\n",
       "1                2723 North Bogan Road  EV_2022_2020    polling  34.10593   \n",
       "2               2735 Old Auburn Avenue  EV_2022_2020    polling  33.99610   \n",
       "3  6400 Sugarloaf Parkway Building 300       EV_2022    polling  33.99165   \n",
       "4                    55 Buford Highway  EV_2022_2020    polling  34.05925   \n",
       "\n",
       "   Longitude  \n",
       "0  -83.98723  \n",
       "1  -83.96820  \n",
       "2  -83.89283  \n",
       "3  -84.09391  \n",
       "4  -84.05714  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the polling location data \n",
    "\n",
    "LOCATION_SOURCE_FILE = 'datasets/polling/EV_Gwinnett_GA.csv'\n",
    "\n",
    "LOCATIONS_COLS = [\n",
    "    'Location',\n",
    "    'Address',\n",
    "    'Location type', \n",
    "    'Lat, Long',\n",
    "]\n",
    "\n",
    "locations = pd.read_csv(LOCATION_SOURCE_FILE)\n",
    "locations = locations[LOCATIONS_COLS]\n",
    "#add a destination type column\n",
    "locations['dest_type'] = 'polling'\n",
    "locations['dest_type'].mask(locations['Location type'].str.contains('Potential'), 'potential', inplace=True)\n",
    "\n",
    "#change the lat, long into two columns\n",
    "locations[['Latitude', 'Longitude']] = locations['Lat, Long'].str.split(pat = ', ', expand=True).astype(float)\n",
    "locations.drop(['Lat, Long'], axis =1, inplace = True)\n",
    "#set(locations['Location type'])\n",
    "locations.head()\n",
    "\n",
    "# Load the census block shape file using geopandas and filter out unneeded columns\n",
    "\n",
    "BLOCK_GROUP_SOURCE_FILE = 'datasets/census/tiger/Gwinnett_GA/tl_2020_13135_bg20.shp'\n",
    "\n",
    "BLOCK_GROUP_SHAPE_COLS = [\n",
    "    'GEOID20',\n",
    "    'INTPTLAT20', \n",
    "    'INTPTLON20',\n",
    "]\n",
    "\n",
    "blockgroup_gdf = gpd.read_file(BLOCK_GROUP_SOURCE_FILE)\n",
    "blockgroup_gdf = blockgroup_gdf[BLOCK_GROUP_SHAPE_COLS]\n",
    "\n",
    "#rename to match locations data \n",
    "blockgroup_gdf = blockgroup_gdf.rename(columns = {'GEOID20': 'Location', 'INTPTLAT20':'Latitude', 'INTPTLON20':'Longitude'})\n",
    "blockgroup_gdf['Address'] = None\n",
    "blockgroup_gdf['Location type'] = 'bg_centroid'\n",
    "\n",
    "\n",
    "#Concatenate\n",
    "all_locations = pd.concat([locations, blockgroup_gdf])\n",
    "\n",
    "#Lat and Long current mix of string and geometry. Make them all floats\n",
    "all_locations['Latitude'] = pd.to_numeric(all_locations['Latitude'])\n",
    "all_locations['Longitude'] = pd.to_numeric(all_locations['Longitude'])\n",
    "\n",
    "if len(all_locations.Location) != len(set(all_locations.Location)):\n",
    "    raise ValueError('Non-unique names in Location column. This will cause errors later.')\n",
    "\n",
    "#make locations into geopandas objects\n",
    "#all_locations = gpd.GeoDataFrame(\n",
    "#    all_locations, geometry=gpd.points_from_xy(all_locations.Longitude, all_locations.Latitude), #crs=\"ESRI:103263\"\n",
    "#).to_crs(\"ESRI:103263\")\n",
    "#print(all_locations.crs.axis_info[0].unit_name)\n",
    "all_locations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ddd1592",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross join polling location data with the census data, and compute straight line distances\n",
    "\n",
    "full_df = combined_df.merge(all_locations, how= 'cross')\n",
    "\n",
    "full_df['distance_m'] = full_df.apply(lambda row: haversine((row.INTPTLAT20, row.INTPTLON20), (row.Latitude, row.Longitude)), axis=1)*1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "808cbbba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4125726, 20)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#full_df[['INTPTLAT20', 'INTPTLON20', 'Location', 'Address', 'Latitude', 'Longitude', 'distances_m']].head()\n",
    "#prepare data for writing\n",
    "\n",
    "full_df = full_df.rename(columns = {'GEO_ID': 'id_orig', 'Address': 'address', 'Latitude':'dest_lat', 'Longitude':'dest_lon', 'INTPTLAT20':'orig_lat', 'INTPTLON20':'orig_lon'})\n",
    "full_df['location'] = 'Gwinnett_GA'\n",
    "full_df['id_dest'] = full_df['Location'] +\"-\"+ full_df['Location type']\n",
    "\n",
    "FULL_DF_COLS = [\n",
    "    'id_orig',\n",
    "    'id_dest',\n",
    "    'distance_m',\n",
    "    'location',\n",
    "    'address',\n",
    "    'dest_lat',\n",
    "    'dest_lon',\n",
    "    'orig_lat',\n",
    "    'orig_lon',\n",
    "    'dest_type',\n",
    "    'population',\n",
    "    'hispanic', \n",
    "    'non-hispanic',\n",
    "    'white', \n",
    "    'black', \n",
    "    'native', \n",
    "    'asian',\n",
    "    'pacific_islander', \n",
    "    'other', \n",
    "    'multiple_races',\n",
    "]\n",
    "\n",
    "full_df = full_df[FULL_DF_COLS]\n",
    "\n",
    "full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b218dcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to file\n",
    "full_df.to_csv('datasets/Gwinnett_GA.csv', index = True)\n",
    "all_locations.to_csv('datasets/Gwinnett_GA_justlocations.csv', index = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
