{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "904b5911-b647-448b-961f-a93b9c44b895",
   "metadata": {},
   "source": [
    "# Build GA 2020 Source Data\n",
    "\n",
    "This notebook accepts the Census 2020 DHC data and polling location data to build a csv to be used with scip.  Clone this notebook for new states or years.\n",
    "\n",
    "## Census Data:\n",
    "\n",
    "### 2020 Redistricting [P4 group](https://api.census.gov/data/2010/dec/sf1/groups/P4.html)\n",
    "[HISPANIC OR LATINO, AND NOT HISPANIC OR LATINO BY RACE FOR THE POPULATION 18 YEARS AND OVER](https://data.census.gov/table?g=050XX00US13135$1000000&d=DEC+Redistricting+Data+(PL+94-171)&tid=DECENNIALPL2020.P4)\n",
    "1. Select Geography:\n",
    "   1. Filter for Geography -> Blocks -> State -> County Name, State -> All Blocks within County Name, State\n",
    "   1. If asked to select table vintage, select 2020;  DEC Redistricting Data (PL-94-171)\n",
    "\n",
    "Columns we want from P4:\n",
    "* Total population\n",
    "* Total hispanic\n",
    "* Total non-hispanic\n",
    "\n",
    "### 2020 Redistricting [P3 group](https://api.census.gov/data/2010/dec/sf1/groups/P3.html)\n",
    "Data source that includes Race and geography: \n",
    "[RACE FOR THE POPULATION 18 YEARS AND OVER](https://data.census.gov/table?q=P3:+RACE+FOR+THE+POPULATION+18+YEARS+AND+OVER&tid=DECENNIALPL2020.P3)\n",
    "1. Select Geography:\n",
    "   1. Filter for Geography -> Blocks -> State -> County Name, State -> All Blocks within County Name, State\n",
    "   1. If asked to select table vintage, select 2020;  DEC Redistricting Data (PL-94-171)\n",
    "\n",
    "Colums we want from P3:\n",
    "* White alone\n",
    "* Black or African American alone\n",
    "* American Indian And Alaska Native alone\n",
    "* Asian alone\n",
    "* Native Hawaiian and Other Pacific Islander alone\n",
    "* Some Other Race alone\n",
    "* Two or More Races\n",
    "\n",
    "\n",
    "### 2020 Tiger/Line Shapefiles: Blocks (2020) \n",
    "Source Data https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.2020.html#list-tab-790442341\n",
    "* Scroll down to FTP Archiv by State\n",
    "* Click on desired States\n",
    "* Click on desired FIPS Code for the County\n",
    "* Download that *_tablock20.zip and the *_bg20.zip files\n",
    "\n",
    "Documentation: https://www.census.gov/programs-surveys/geography/technical-documentation/complete-technical-documentation/tiger-geo-line/2020.html\n",
    "\n",
    "Columns we want from blocks:\n",
    "* GEO_ID - obtained by converting values in GEOID20 column and preppending \"1000000US\", e.g. 131510703153004 -> 1000000US131510703153004\n",
    "* geometry - the polygon of the block\n",
    "* INTPTLAT20 - latitude of block centroid\n",
    "* INTPTLON20 - longitude of block centroid\n",
    "\n",
    "**Susama:** please verify the above\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\n",
    "## Redistricting source data:\n",
    "1. Download desired Census Data\n",
    "   1. P4 zip file from Census\n",
    "   1. P3 zip file from Census\n",
    "   1. Recommend downloading one county's worth of data at a time.\n",
    "1. Create a directory to datasets/census/redistricting/County_Name_ST **Chad**: This is a change to  your folder structure. I want to indicate geography in the name\n",
    "   1. E.g datasets/census/redistricting/Gwinett_GA\n",
    "   1. Key files: DECENNIALPL2020.P3-Data.csv; DECENNIALPL2020.P4-Data.csv\n",
    "   1. Note, this requires one to filter for an individual county from the census.\n",
    "1. Unzip the downloaded file P11 file zip to the directory \n",
    "\n",
    "## Tiger/Line Shapefile\n",
    "1. Download desired Tiger/Line file zip file from Census\n",
    "1. Create a directory to datasets/census/tiger/County_Name_St e.g. datasets/census/tiger/Gwinett_GA\n",
    "1. Unzip the downloaded Tiger/Line zip file to the directory \n",
    "    \n",
    "## Run cells\n",
    "1. Update constants such as P11_SOURCE_FILE, P3_SOURCE_FILE, BLOCK_SOURCE_FILE as needed\n",
    "1. Run each cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d5027b87-ac41-4bf9-80b1-056a59a54865",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the P11 csv source data into a data frame and filter out unneeded columns\n",
    "\n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "from haversine import haversine, Unit\n",
    "import geopandas as gpd\n",
    "\n",
    "P4_SOURCE_FILE = 'datasets/census/redistricting/Gwinett_GA/DECENNIALPL2020.P4-Data.csv'\n",
    "P3_SOURCE_FILE = 'datasets/census/redistricting/Gwinett_GA/DECENNIALPL2020.P3-Data.csv'\n",
    "\n",
    "# The column in the P4 and P4data that contains the GEO id.  This will be used later to join\n",
    "# against the Block Shape File\n",
    "P4_GEOID = 'GEO_ID'\n",
    "P3_GEOID = 'GEO_ID'\n",
    "\n",
    "# Prefix to add to Shape files to join them with this P11.  Note this\n",
    "# needs to match the prefix found in GEO_ID output from this cell.\n",
    "GEO_ID_PREFIX = '1000000US'\n",
    "\n",
    "PL_P4_COLUMNS = [\n",
    "    P4_GEOID,\n",
    "    'NAME',\n",
    "    'P4_001N', # Total population\n",
    "    'P4_002N', # Total hispanic\n",
    "    'P4_003N', # Total non-hispanic\n",
    "]\n",
    "\n",
    "PL_P3_COLUMNS = [\n",
    "    P3_GEOID,\n",
    "    'NAME',\n",
    "    'P3_001N', # Total population\n",
    "    'P3_002N', # White alone\n",
    "    'P3_003N', # Black or African American alone\n",
    "    'P3_004N', # American Indian or Alaska Native alone\n",
    "    'P3_005N', # Asian alone\n",
    "    'P3_006N', # Native Hawaiian and Other Pacific Islander alone\n",
    "    'P3_007N', # Some other race alone \n",
    "    'P3_008N', # Two or More Races   \n",
    "]\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "#print('DHC P11 File')\n",
    "#print(f'  Source {P11_SOURCE_FILE}')\n",
    "\n",
    "p4_df = pd.read_csv(\n",
    "    P4_SOURCE_FILE,\n",
    "    header=[0,1], # DHC files have two headers rows when exported to CSV - tell pandas to only take top one\n",
    "    low_memory=False, # files are too big, set this to False to prevent errors\n",
    "    # nrows=10, # limit rows loaded - testing purposes only\n",
    ")\n",
    "\n",
    "p3_df = pd.read_csv(\n",
    "    P3_SOURCE_FILE,\n",
    "    header=[0,1], # DHC files have two headers rows when exported to CSV - tell pandas to take top one\n",
    "    low_memory=False, # files are too big, set this to False to prevent errors\n",
    "    # nrows=10, # limit rows loaded - testing purposes only\n",
    ")\n",
    "\n",
    "\n",
    "# Filter out the un-needed columns and keep only one header\n",
    "p4_df = p4_df[PL_P4_COLUMNS]\n",
    "p4_df.columns = p4_df.columns=[multicols[0] for multicols in p4_df.columns]\n",
    "\n",
    "p3_df = p3_df[PL_P3_COLUMNS]\n",
    "p3_df.columns = p3_df.columns=[multicols[0] for multicols in p3_df.columns]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ec9b87ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GEO_ID', 'NAME', 'hispanic', 'non-hispanic', 'population', 'white',\n",
       "       'black', 'native', 'asian', 'pacific_islander', 'other',\n",
       "       'multiple_races'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merge the data sets to get a joint demographics set\n",
    "demographics = p4_df.merge(p3_df, left_on=['GEO_ID', 'NAME'], right_on=['GEO_ID', 'NAME'],how = 'outer')\n",
    "\n",
    "#Consistency check for the data pull\n",
    "demographics['Pop_diff'] = demographics.P4_001N- demographics.P3_001N\n",
    "if demographics.loc[demographics.Pop_diff != 0].shape[0]!=0:\n",
    "    raise ValueError('Populations different in P3 and P4. Are both pulled from the voting age universe?')\n",
    "\n",
    "#Change column names\n",
    "demographics.drop(['P4_001N', 'Pop_diff'], axis =1, inplace = True)\n",
    "demographics = demographics.rename(columns = {'P4_002N': 'hispanic', 'P4_003N':'non-hispanic', 'P3_001N':'population', 'P3_002N':'white', 'P3_003N':'black', \n",
    "                      'P3_004N':'native', 'P3_005N':'asian', 'P3_006N':'pacific_islander', 'P3_007N':'other', 'P3_008N':'multiple_races'})\n",
    "#Note, Hispanic is an ethnicity, not a race. The P4 columns add to the total population. The P3 columns add to the total population\n",
    "demographics.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "283d1c07-85e4-467a-8099-211e332bbdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the census block shape file using geopandas and filter out unneeded columns\n",
    "\n",
    "BLOCK_SOURCE_FILE = 'datasets/census/tiger/Gwinett_GA/tl_2020_13135_tabblock20.shp'\n",
    "\n",
    "BLOCK_SHAPE_COLS = [\n",
    "    'GEOID20',\n",
    "    'INTPTLAT20', \n",
    "    'INTPTLON20',\n",
    "]\n",
    "\n",
    "blocks_gdf = gpd.read_file(BLOCK_SOURCE_FILE)\n",
    "blocks_gdf = blocks_gdf[BLOCK_SHAPE_COLS]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c040b938-6549-4d87-9171-28d4c6f67d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GEO_ID               object\n",
       "NAME                 object\n",
       "hispanic              int64\n",
       "non-hispanic          int64\n",
       "population            int64\n",
       "white                 int64\n",
       "black                 int64\n",
       "native                int64\n",
       "asian                 int64\n",
       "pacific_islander      int64\n",
       "other                 int64\n",
       "multiple_races        int64\n",
       "GEOID20              object\n",
       "INTPTLAT20          float64\n",
       "INTPTLON20          float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the PL demographic data with the block groups shape file using a join on GEO IDs\n",
    "#drop geo_id_prefix\n",
    "demographics['GEO_ID'] = demographics['GEO_ID'].str.replace(GEO_ID_PREFIX, '')\n",
    "\n",
    "combined_df = demographics.merge(blocks_gdf, left_on='GEO_ID', right_on = 'GEOID20',how='left')\n",
    "\n",
    "#make lat/ long floats\n",
    "combined_df.INTPTLAT20 = combined_df.INTPTLAT20.astype(float)\n",
    "combined_df.INTPTLON20 = combined_df.INTPTLON20.astype(float)\n",
    "\n",
    "combined_df.dtypes\n",
    "#make combined_df into geopandas objects\n",
    "\n",
    "#combined_df = gpd.GeoDataFrame(\n",
    "#    combined_df, geometry=gpd.points_from_xy(combined_df.INTPTLON20, combined_df.INTPTLAT20), crs=\"ESRI:103263\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "bc492a05-3bd6-431c-a67c-2b87730b78ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>Address</th>\n",
       "      <th>Location type</th>\n",
       "      <th>dest_type</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aurora Theater</td>\n",
       "      <td>128 E Pike St</td>\n",
       "      <td>Potential</td>\n",
       "      <td>potential</td>\n",
       "      <td>33.95711</td>\n",
       "      <td>-83.98723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bogan Park Community Recreation Center</td>\n",
       "      <td>2723 North Bogan Road</td>\n",
       "      <td>EV_2022_2020</td>\n",
       "      <td>polling</td>\n",
       "      <td>34.10593</td>\n",
       "      <td>-83.96820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dacula Park Activity Building</td>\n",
       "      <td>2735 Old Auburn Avenue</td>\n",
       "      <td>EV_2022_2020</td>\n",
       "      <td>polling</td>\n",
       "      <td>33.99610</td>\n",
       "      <td>-83.89283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gas South-Hudgens Center for Arts</td>\n",
       "      <td>6400 Sugarloaf Parkway Building 300</td>\n",
       "      <td>EV_2022</td>\n",
       "      <td>polling</td>\n",
       "      <td>33.99165</td>\n",
       "      <td>-84.09391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>George Pierce Park Community Recreation Center</td>\n",
       "      <td>55 Buford Highway</td>\n",
       "      <td>EV_2022_2020</td>\n",
       "      <td>polling</td>\n",
       "      <td>34.05925</td>\n",
       "      <td>-84.05714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Location   \n",
       "0                                  Aurora Theater  \\\n",
       "1          Bogan Park Community Recreation Center   \n",
       "2                   Dacula Park Activity Building   \n",
       "3               Gas South-Hudgens Center for Arts   \n",
       "4  George Pierce Park Community Recreation Center   \n",
       "\n",
       "                               Address Location type  dest_type  Latitude   \n",
       "0                        128 E Pike St     Potential  potential  33.95711  \\\n",
       "1                2723 North Bogan Road  EV_2022_2020    polling  34.10593   \n",
       "2               2735 Old Auburn Avenue  EV_2022_2020    polling  33.99610   \n",
       "3  6400 Sugarloaf Parkway Building 300       EV_2022    polling  33.99165   \n",
       "4                    55 Buford Highway  EV_2022_2020    polling  34.05925   \n",
       "\n",
       "   Longitude  \n",
       "0  -83.98723  \n",
       "1  -83.96820  \n",
       "2  -83.89283  \n",
       "3  -84.09391  \n",
       "4  -84.05714  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the polling location data \n",
    "\n",
    "LOCATION_SOURCE_FILE = 'datasets/polling/EV_Gwinett_GA.csv'\n",
    "\n",
    "LOCATIONS_COLS = [\n",
    "    'Location',\n",
    "    'Address',\n",
    "    'Location type', \n",
    "    'Lat, Long',\n",
    "]\n",
    "\n",
    "locations = pd.read_csv(LOCATION_SOURCE_FILE)\n",
    "locations = locations[LOCATIONS_COLS]\n",
    "#add a destination type column\n",
    "locations['dest_type'] = 'polling'\n",
    "locations['dest_type'].mask(locations['Location type'].str.contains('Potential'), 'potential', inplace=True)\n",
    "\n",
    "#change the lat, long into two columns\n",
    "locations[['Latitude', 'Longitude']] = locations['Lat, Long'].str.split(pat = ', ', expand=True).astype(float)\n",
    "locations.drop(['Lat, Long'], axis =1, inplace = True)\n",
    "#set(locations['Location type'])\n",
    "locations.head()\n",
    "\n",
    "# Load the census block shape file using geopandas and filter out unneeded columns\n",
    "\n",
    "BLOCK_GROUP_SOURCE_FILE = 'datasets/census/tiger/Gwinett_GA/tl_2020_13135_bg20.shp'\n",
    "\n",
    "BLOCK_GROUP_SHAPE_COLS = [\n",
    "    'GEOID20',\n",
    "    'INTPTLAT20', \n",
    "    'INTPTLON20',\n",
    "]\n",
    "\n",
    "blockgroup_gdf = gpd.read_file(BLOCK_GROUP_SOURCE_FILE)\n",
    "blockgroup_gdf = blockgroup_gdf[BLOCK_GROUP_SHAPE_COLS]\n",
    "\n",
    "#rename to match locations data \n",
    "blockgroup_gdf = blockgroup_gdf.rename(columns = {'GEOID20': 'Location', 'INTPTLAT20':'Latitude', 'INTPTLON20':'Longitude'})\n",
    "blockgroup_gdf['Address'] = None\n",
    "blockgroup_gdf['Location type'] = 'bg_centroid'\n",
    "\n",
    "\n",
    "#Concatenate\n",
    "all_locations = pd.concat([locations, blockgroup_gdf])\n",
    "\n",
    "#Lat and Long current mix of string and geometry. Make them all floats\n",
    "all_locations['Latitude'] = pd.to_numeric(all_locations['Latitude'])\n",
    "all_locations['Longitude'] = pd.to_numeric(all_locations['Longitude'])\n",
    "\n",
    "if len(all_locations.Location) != len(set(all_locations.Location)):\n",
    "    raise ValueError('Non-unique names in Location column. This will cause errors later.')\n",
    "\n",
    "#make locations into geopandas objects\n",
    "#all_locations = gpd.GeoDataFrame(\n",
    "#    all_locations, geometry=gpd.points_from_xy(all_locations.Longitude, all_locations.Latitude), #crs=\"ESRI:103263\"\n",
    "#).to_crs(\"ESRI:103263\")\n",
    "#print(all_locations.crs.axis_info[0].unit_name)\n",
    "all_locations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "7ddd1592",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross join polling location data with the census data, and compute straight line distances\n",
    "\n",
    "full_df = combined_df.merge(all_locations, how= 'cross')\n",
    "\n",
    "#full_df['distance_m'] =  full_df.apply(lambda row: row[\"geometry_x\"].distance(row[\"geometry_y\"]), axis=1)\n",
    "\n",
    "full_df['distance_m'] = full_df.apply(lambda row: haversine((row.INTPTLAT20, row.INTPTLON20), (row.Latitude, row.Longitude)), axis=1)*1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "808cbbba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_orig</th>\n",
       "      <th>id_dest</th>\n",
       "      <th>distance_m</th>\n",
       "      <th>location</th>\n",
       "      <th>address</th>\n",
       "      <th>dest_lat</th>\n",
       "      <th>dest_lon</th>\n",
       "      <th>orig_lat</th>\n",
       "      <th>orig_lon</th>\n",
       "      <th>dest_type</th>\n",
       "      <th>population</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>non-hispanic</th>\n",
       "      <th>white</th>\n",
       "      <th>black</th>\n",
       "      <th>native</th>\n",
       "      <th>asian</th>\n",
       "      <th>pacific_islander</th>\n",
       "      <th>other</th>\n",
       "      <th>multiple_races</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>131350501051000</td>\n",
       "      <td>Aurora Theater-Potential</td>\n",
       "      <td>19876.420317</td>\n",
       "      <td>Gwinett_GA</td>\n",
       "      <td>128 E Pike St</td>\n",
       "      <td>33.95711</td>\n",
       "      <td>-83.98723</td>\n",
       "      <td>34.135637</td>\n",
       "      <td>-83.976393</td>\n",
       "      <td>potential</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>131350501051000</td>\n",
       "      <td>Bogan Park Community Recreation Center-EV_2022...</td>\n",
       "      <td>3388.266313</td>\n",
       "      <td>Gwinett_GA</td>\n",
       "      <td>2723 North Bogan Road</td>\n",
       "      <td>34.10593</td>\n",
       "      <td>-83.96820</td>\n",
       "      <td>34.135637</td>\n",
       "      <td>-83.976393</td>\n",
       "      <td>polling</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id_orig                                            id_dest   \n",
       "0  131350501051000                           Aurora Theater-Potential  \\\n",
       "1  131350501051000  Bogan Park Community Recreation Center-EV_2022...   \n",
       "\n",
       "     distance_m    location                address  dest_lat  dest_lon   \n",
       "0  19876.420317  Gwinett_GA          128 E Pike St  33.95711 -83.98723  \\\n",
       "1   3388.266313  Gwinett_GA  2723 North Bogan Road  34.10593 -83.96820   \n",
       "\n",
       "    orig_lat   orig_lon  dest_type  population  hispanic  non-hispanic  white   \n",
       "0  34.135637 -83.976393  potential           2         0             2      2  \\\n",
       "1  34.135637 -83.976393    polling           2         0             2      2   \n",
       "\n",
       "   black  native  asian  pacific_islander  other  multiple_races  \n",
       "0      0       0      0                 2      0               0  \n",
       "1      0       0      0                 2      0               0  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#full_df[['INTPTLAT20', 'INTPTLON20', 'Location', 'Address', 'Latitude', 'Longitude', 'distances_m']].head()\n",
    "#prepare data for writing\n",
    "\n",
    "full_df = full_df.rename(columns = {'GEO_ID': 'id_orig', 'Address': 'address', 'Latitude':'dest_lat', 'Longitude':'dest_lon', 'INTPTLAT20':'orig_lat', 'INTPTLON20':'orig_lon'})\n",
    "full_df['location'] = 'Gwinett_GA'\n",
    "full_df['id_dest'] = full_df['Location'] +\"-\"+ full_df['Location type']\n",
    "\n",
    "FULL_DF_COLS = [\n",
    "    'id_orig',\n",
    "    'id_dest',\n",
    "    'distance_m',\n",
    "    'location',\n",
    "    'address',\n",
    "    'dest_lat',\n",
    "    'dest_lon',\n",
    "    'orig_lat',\n",
    "    'orig_lon',\n",
    "    'dest_type',\n",
    "    'population',\n",
    "    'hispanic', \n",
    "    'non-hispanic',\n",
    "    'white', \n",
    "    'black', \n",
    "    'native', \n",
    "    'asian',\n",
    "    'pacific_islander', \n",
    "    'other', \n",
    "    'multiple_races',\n",
    "]\n",
    "\n",
    "full_df = full_df[FULL_DF_COLS]\n",
    "\n",
    "full_df.head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "b218dcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to file\n",
    "full_df.to_csv('datasets/Gwinett_GA.csv', index = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
