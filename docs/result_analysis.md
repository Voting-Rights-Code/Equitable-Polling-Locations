# Result Analysis
After the data is generated by the optimizer, a function in the `result_analysis/` folder generates graphs, maps, regressions etc. for the resulting datasets. The output images and .csvs for a config_folder (or config_set) are placed in a the folder `result_analysis_outputs/` folder as well as the Google CloudStorage bucket indicated in the file.

## Overall workflow
Whether pulling from the database or csv, the analysis software compiles the relevant data as follows:
1. Pull all the data from the indicated config_sets
    1. The graphs need the all the data for a config_set together
    1. The maps need each config_name, config_set pair separately
1. Performs safety checks
    1. That the data pulled varies by only one field per set
    1. That the data contains the locations of interest
1. Pulls out a Driving and a Log Flag from the config file
1. Reads and coallates data by the four tables
    1. This includes and autmatic generation of a descriptor field based off the field that varies
    1. This descriptor field may need to be mannually changed, depending on the specifics of the data.
1. For mapping, this is then combined with block group level demographic data, block group level distances are calculated and each config_name, config_set pair is split into its own datatable
1. Graphs are made and stored
    1. edes and average distances by population are plotted together for an indicated set of config_names
    1. edes by demographic are plogged for a given config_set
    1. a plot of which precincts are chosen, for which optimization, how many people are assigned for all config_names in a config_set
    1. A histogram comparing the distributions of how far people travel for an indicated set of config_names
1. Maps are made and stored
    1. A heat map of how far people have to travel with polling locations indicated
    1. A head map of how far people of a given demographic have to travel. 

## To run
There are several different analysis files currently in `R/result_analysis`. The one used most commonly used is `Basic_analysis.r`. For other examples that haven't been updated to run from command line, see `R/result_analysis/deprecated`.
1. put `Rscript` in `PATH` for your system
2. Create an analysis script (e.g. `Basic_analysis.r`)
3. Store all constants needed for the file in a config folder that indicates the correct file to run it on. (e.g. `R/result_analysis/Basic_analysis_configs/`)
4. From terminal, run `Rscript R/result_analysis/Basic_analysis.r name_of_config.r`. Note, name_of_config is only the file name, not the path. E.g `Berkeley_County_original.r`.

# Analysis and Google Cloud Storage

By default output from R analysis will be written to Google Cloud Storage under the bucket `equitable-polling-analysis` under the folder `result_analysis`. This bucket can be browsed in the [Google Cloud Storage](https://console.cloud.google.com/storage/browser/equitable-polling-analysis;tab=objects?forceOnBucketsSortingFiltering=true&project=equitable-polling-locations&prefix=&forceOnObjectsSortingFiltering=false) console, if access is grated.

## Database

When running analsyis in R, such as the `.../result_analysis/Basic_analsysis.r`, data can be read from the local csv files or from
a BigQuery dataset.  If data is desired from the database, set READ_FROM_CSV to FALSE, such as:

```R
READ_FROM_CSV = FALSE
```

Database authentication will happen automatically via the [`bigrquery` R library](https://bigrquery.r-dbi.org/).

To set which database to use, set the `PROJECT`, `DATASET`, and `BILLING` variables, such as the following:

```R
PROJECT = "equitable-polling-locations"
DATASET = "equitable_polling_locations_prod"
BILLING = PROJECT
```

## Google CloudStorage

To write the output of analysis to the Google Cloud Cloud storage, at the end of the analysis file make sure the following variables are set.

| Variable Name               | Description                                                                                 |
|-----------------------------|---------------------------------------------------------------------------------------------|
| STORAGE_BUCKET              | The google cloud storage bucket to write to.                                                |
| CLOUD_STORAGE_ANALYSIS_NAME | The name of the folder to write all the analysis to under the folder `.../result_analysis/` |


And at the end of the R file, add the following line:

```R
upload_graph_files_to_cloud_storage()
```

Authentication will happen via the [`googleCloudStorageR` R library](https://CRAN.R-project.org/package=googleCloudStorageR).  Before running the R analysis, you must login via the [gcloud command line tool](https://cloud.google.com/sdk/docs/install-sdk).  One installed, run the following:

```
gcloud auth application-default login
```


Example:
```R
# ...

STORAGE_BUCKET = "equitable-polling-analysis"
CLOUD_STORAGE_ANALYSIS_NAME = "Basic_analysis.r"

# ...

###maps####

sapply(orig_list_prepped, function(x)make_bg_maps(x, 'map'))

sapply(orig_list_prepped, function(x)make_demo_dist_map(x, 'population'))
sapply(orig_list_prepped, function(x)make_demo_dist_map(x, 'black'))
sapply(orig_list_prepped, function(x)make_demo_dist_map(x, 'white'))
sapply(orig_list_prepped, function(x)make_demo_dist_map(x, 'hispanic'))
sapply(orig_list_prepped, function(x)make_demo_dist_map(x, 'asian'))

upload_graph_files_to_cloud_storage()
```

By setting the above, any graph file written to using the functions found in `.../result_analysis/graph_functions.R` and `.../result_analysis/graph_functions.R` will be written locally in the `.../result_analysis/` as well as to Cloud Storage under the folder `equitable-polling-analysis:result_analysis/Basic_analysis.r/[DATESTAMP]/...`.

